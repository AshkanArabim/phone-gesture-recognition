{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":126,"status":"ok","timestamp":1690235379405,"user":{"displayName":"Ashkan Arabi","userId":"00016294364162523281"},"user_tz":240},"id":"hQVSzy2lsw3w"},"outputs":[],"source":["from google.colab import drive\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import json\n","import os\n","import pprint as pp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":746,"status":"ok","timestamp":1690235380290,"user":{"displayName":"Ashkan Arabi","userId":"00016294364162523281"},"user_tz":240},"id":"74Wfj4ep7odq","outputId":"c1dd1a92-0a25-431f-e80b-09a7133cb8f9"},"outputs":[],"source":["drive.mount('/Drive')\n","!ln -s '/Drive/MyDrive/google_colab_files_for_CSI' '/content/REU'\n","root_data_path = os.path.join('REU','csi_data_all')\n","REU = os.path.join('REU')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":138,"status":"ok","timestamp":1690238620346,"user":{"displayName":"Ashkan Arabi","userId":"00016294364162523281"},"user_tz":240},"id":"L5Yr5Ugts-UG"},"outputs":[],"source":["from matplotlib.font_manager import FontProperties\n","# For each person, index 0 is the precision, index 1 is the recall.\n","# I may automate this in the future if it bothers me enough\n","\n","def join(*args): # makes life easier\n","    return os.path.join(*args)\n","\n","def add_json_to_dict(path, existing_dict): # problematic\n","    # # DEBUG\n","    # print(f'adding {path}')\n","\n","    with open(path, 'r') as file:\n","        new_dict = json.load(file)\n","    # pp.pprint(new_dict) # DEBUG\n","\n","    for key, value in existing_dict.items():\n","        existing_dict[key] = existing_dict[key] + [new_dict[key]] # new dict is one dimension lower\n","\n","    return existing_dict\n","\n","def array_vals_to_numpy(data_dict):\n","    updated_dict = {}\n","    for key, arr in data_dict.items():\n","        updated_dict[key] = np.asarray(arr)\n","    return updated_dict\n","\n","def get_label(impact_factor):\n","    i = impact_factor\n","    if i == 'dist-phone': return 'Distance of Phone'\n","    if i == 'dist-AP': return 'Distance of AP'\n","    if i == 'data-points': return 'Number of Datasets'\n","    return i.capitalize()\n","\n","def group_bar_chart(impact_factor, data_dict, groups, exclude = [], save_path = None):\n","    # set everything to bold\n","    plt.rcParams['font.weight'] = 'bold'\n","\n","    # DEBUG\n","    # print('data_dict', data_dict) # wrong order\n","\n","    data_dict = array_vals_to_numpy(data_dict)\n","    fig, ax = plt.subplots(figsize = (4, 3))\n","\n","    x = np.arange(len(groups))\n","    width = 0.3\n","    multiplier = 0\n","    # global_min = 100 # initialize to largest possible value\n","\n","    # get the f1 score of each gesture\n","    # f1 = (precision * recall) / (precision + recall)\n","    data_dict['f1'] = 2 * (data_dict['precision'] * data_dict['recall']) / (data_dict['precision'] + data_dict['recall'])\n","\n","    # print('f1 array:')\n","    # pp.pprint(data_dict['f1'])\n","\n","    # print(global_min) # CORRECT\n","    # print(int(global_min))\n","\n","    # ex: precision [[], []]\n","    for attribute, attribute_values in data_dict.items():\n","        if attribute in exclude:\n","            continue\n","\n","        # attribute_values = [precision1, precision2]\n","        # DEBUG\n","        # print('attribute_values:', attribute_values)\n","        attribute_values = np.average(attribute_values, axis = 1) * 100\n","        # print(f'{attribute}:', attribute_values)\n","\n","        # print('attribute_values', attribute_values) # debug\n","\n","        val_min = np.min(attribute_values)\n","        # if val_min < global_min: global_min = val_min\n","\n","        offset = multiplier * width\n","        bars = ax.bar(x + offset, attribute_values, width, label = attribute.capitalize())\n","\n","        if len(groups) < 4:\n","            ax.bar_label(bars, labels = np.round(attribute_values, 2), label_type = 'center')\n","        multiplier += 1\n","\n","    # print(int(global_min))\n","    ax.set_ylim((80, 100))\n","\n","    ax.set_xlabel(get_label(impact_factor), weight = 'bold')\n","    ax.set_ylabel(get_label('percentage'), weight = 'bold')\n","    ax.set_xticks(x + width / 2, groups)\n","    # ax.bar_label() # DEBUG\n","\n","    plt.legend()\n","    plt.tight_layout(pad=0., w_pad=10, h_pad=5)\n","    if save_path:\n","        print(f'saving in {save_path}')\n","        plt.savefig(save_path)\n","    plt.show()\n","\n","def generate_plots(impact_factor):\n","    # import impact factor jsons\n","    plots_location = join('REU')\n","    data_files_parent = join(REU, 'paper_charts')\n","    data_file_names = sorted(os.listdir(data_files_parent))\n","    data_file_names = list(filter(lambda x: impact_factor in x, data_file_names)) # limit to only files relevant to this impact factor\n","    data_json_names = list(filter(lambda x: '.json' in x, data_file_names)) # select json files\n","\n","    impact_factor_data_dict = { # data will be stored in this dict\n","        'accuracy': [],\n","        'precision': [],\n","        'recall': [],\n","    }\n","\n","    # defnie the groups by looking at the file names\n","    groups = list(map(lambda filename: filename.split('_')[1].split('.')[0], data_json_names))\n","\n","    for json_name in data_json_names:\n","        impact_factor_data_dict = add_json_to_dict(\n","            join(data_files_parent, json_name),\n","            impact_factor_data_dict,\n","        ) # update impact_factor data\n","\n","    # DEBUG\n","    print('impact_factor:', impact_factor)\n","    # print('impact_factor_data_dict:', impact_factor_data_dict)\n","    print('groups:', groups)\n","\n","    group_bar_chart(\n","        impact_factor,\n","        impact_factor_data_dict,\n","        groups,\n","        exclude = ['precision','recall'],\n","        save_path = join(data_files_parent, f'{impact_factor}_compared.pdf')\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2466,"status":"ok","timestamp":1690238622810,"user":{"displayName":"Ashkan Arabi","userId":"00016294364162523281"},"user_tz":240},"id":"iSBAVwFmAHXf","outputId":"60048600-d4b8-4b07-ae1c-c60534a65609"},"outputs":[],"source":["impact_factors = [\n","    'overall',\n","    'phones',\n","    'people',\n","    'dist-AP',\n","    'dist-phone',\n","    'data-points',\n","]\n","\n","for impact_factor in impact_factors:\n","    generate_plots(impact_factor)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
